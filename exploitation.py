import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import pickle
from bench import APSO_CEC, SPSO_CEC, ARPSO_CEC
from cec import CEC2022Benchmark

def run_one_iteration(algorithm, benchmark):
    if isinstance(algorithm, APSO_CEC):
        positions = algorithm.positions.copy()
        velocities = algorithm.velocities.copy()
        accelerations = algorithm.accelerations.copy()
        
        fitness_values = np.array([benchmark.evaluate(pos) for pos in positions])
        
        b_positions = algorithm.b_positions if hasattr(algorithm, 'b_positions') else positions.copy()
        b_fitness = algorithm.b_scores if hasattr(algorithm, 'b_scores') else fitness_values.copy()
        
        g_index = np.argmin(fitness_values)
        g_position = positions[g_index].copy()
        
        accelerations = algorithm.update_acceleration(accelerations, positions, b_positions, g_position)
        velocities = algorithm.update_velocity(velocities, accelerations)
        positions = algorithm.update_position(positions, velocities)
        
        positions = np.clip(positions, -100, 100)
        
        algorithm.positions = positions
        algorithm.velocities = velocities
        algorithm.accelerations = accelerations
        
        fitness_values = np.array([benchmark.evaluate(pos) for pos in positions])
        
        if hasattr(algorithm, 'b_positions'):
            improved = fitness_values < b_fitness
            algorithm.b_positions[improved] = positions[improved].copy()
            algorithm.b_scores[improved] = fitness_values[improved]
        
        best_idx = np.argmin(fitness_values)
        best_pos = positions[best_idx].copy()
        best_fit = fitness_values[best_idx]
        
        return best_pos, best_fit
    
    elif isinstance(algorithm, SPSO_CEC):
        positions = algorithm.positions.copy()
        velocities = algorithm.velocities.copy()
        
        fitness_values = np.array([benchmark.evaluate(pos) for pos in positions])
        
        b_positions = algorithm.b_positions if hasattr(algorithm, 'b_positions') else positions.copy()
        b_fitness = algorithm.b_scores if hasattr(algorithm, 'b_scores') else fitness_values.copy()
        
        g_index = np.argmin(fitness_values)
        g_position = positions[g_index].copy()
        
        velocities = algorithm.update_velocity(velocities, positions, b_positions, g_position)
        positions = algorithm.update_positions(velocities, positions)
        
        positions = np.clip(positions, -100, 100)
        
        algorithm.positions = positions
        algorithm.velocities = velocities
        
        fitness_values = np.array([benchmark.evaluate(pos) for pos in positions])
        
        if hasattr(algorithm, 'b_positions'):
            improved = fitness_values < b_fitness
            algorithm.b_positions[improved] = positions[improved].copy()
            algorithm.b_scores[improved] = fitness_values[improved]
        
        best_idx = np.argmin(fitness_values)
        best_pos = positions[best_idx].copy()
        best_fit = fitness_values[best_idx]
        
        return best_pos, best_fit
    
    elif isinstance(algorithm, ARPSO_CEC):
        positions = algorithm.positions.copy()
        velocities = algorithm.velocities.copy()
        
        fitness_values = np.array([benchmark.evaluate(pos) for pos in positions])
        
        b_positions = algorithm.b_positions if hasattr(algorithm, 'b_positions') else positions.copy()
        b_fitness = algorithm.b_scores if hasattr(algorithm, 'b_scores') else fitness_values.copy()
        
        g_index = np.argmin(fitness_values)
        g_position = positions[g_index].copy()
        
        attractive_position = np.random.uniform(-100, 100, (algorithm.num_particles, algorithm.dim))
        
        obstacles = np.array([[0, 0]])
        
        w = algorithm.calculate_inertia_weight(fitness_values)
        c3_values = algorithm.calculate_c3(positions, obstacles)
        
        velocities = algorithm.update_velocity(
            velocities, positions, b_positions, g_position, attractive_position, w, c3_values
        )
        positions = algorithm.update_position(positions, velocities)
        
        positions = np.clip(positions, -100, 100)
        
        algorithm.positions = positions
        algorithm.velocities = velocities
        
        fitness_values = np.array([benchmark.evaluate(pos) for pos in positions])
        
        if hasattr(algorithm, 'b_positions'):
            improved = fitness_values < b_fitness
            algorithm.b_positions[improved] = positions[improved].copy()
            algorithm.b_scores[improved] = fitness_values[improved]
        
        best_idx = np.argmin(fitness_values)
        best_pos = positions[best_idx].copy()
        best_fit = fitness_values[best_idx]
        
        return best_pos, best_fit
    
    else:
        raise ValueError(f"Unsupported algorithm type: {type(algorithm)}")

def hybrid_sequential_pso(benchmark, max_iter=200):
    # Phase 1: Use APSO for fast initial convergence (40% of iterations)
    apso = APSO_CEC(num_particles=30, dim=benchmark.dim, max_iter=int(0.4*max_iter))
    best_pos, best_fit, apso_history, apso_positions = apso.optimize(benchmark)
    
    # Phase 2: Use SPSO for fine-tuning (60% of iterations)
    spso = SPSO_CEC(num_particles=30, dim=benchmark.dim, max_iter=int(0.6*max_iter))
    # Initialize SPSO particles around the APSO solution
    spso.positions = best_pos + np.random.normal(0, 5, (30, benchmark.dim))
    final_pos, final_fit, spso_history, spso_positions = spso.optimize(benchmark)
    
    # Combine histories
    combined_history = apso_history + spso_history
    combined_positions = apso_positions + spso_positions
    
    return final_pos, final_fit, combined_history, combined_positions

def hybrid_parallel_pso(benchmark, max_iter=200):
    apso = APSO_CEC(num_particles=10, dim=benchmark.dim, max_iter=max_iter)
    spso = SPSO_CEC(num_particles=10, dim=benchmark.dim, max_iter=max_iter)
    arpso = ARPSO_CEC(num_particles=10, dim=benchmark.dim, max_iter=max_iter)
    
    initial_positions = np.random.uniform(-100, 100, (10, benchmark.dim))
    apso.positions = initial_positions.copy()
    spso.positions = initial_positions.copy()
    arpso.positions = initial_positions.copy()
    
    best_global_pos = None
    best_global_fit = float('inf')
    history = []
    position_history = []
    
    for i in range(max_iter):
        all_positions = np.vstack([apso.positions, spso.positions, arpso.positions])
        position_history.append(all_positions)
        
        apso_pos, apso_fit = run_one_iteration(apso, benchmark)
        spso_pos, spso_fit = run_one_iteration(spso, benchmark)
        arpso_pos, arpso_fit = run_one_iteration(arpso, benchmark)
        
        all_fits = [apso_fit, spso_fit, arpso_fit]
        all_pos = [apso_pos, spso_pos, arpso_pos]
        best_idx = np.argmin(all_fits)
        
        if all_fits[best_idx] < best_global_fit:
            best_global_fit = all_fits[best_idx]
            best_global_pos = all_pos[best_idx]
        
        apso.update_global_best(best_global_pos, best_global_fit)
        spso.update_global_best(best_global_pos, best_global_fit)
        arpso.update_global_best(best_global_pos, best_global_fit)
        
        history.append(best_global_fit)
    
    return best_global_pos, best_global_fit, history, position_history


def hybrid_adaptive_pso(benchmark, max_iter=200):
    apso = APSO_CEC(num_particles=30, dim=benchmark.dim)
    spso = SPSO_CEC(num_particles=30, dim=benchmark.dim)
    arpso = ARPSO_CEC(num_particles=30, dim=benchmark.dim)
    
    initial_positions = np.random.uniform(-100, 100, (30, benchmark.dim))
    apso.positions = initial_positions.copy()
    spso.positions = initial_positions.copy()
    arpso.positions = initial_positions.copy()
    
    performance_window = 10
    algorithm_improvements = {'APSO': 0, 'SPSO': 0, 'ARPSO': 0}
    
    best_global_pos = None
    best_global_fit = float('inf')
    history = []
    position_history = [] 
    current_algorithm = 'APSO'
    
    for i in range(max_iter):
        if current_algorithm == 'APSO':
            position_history.append(apso.positions.copy())
        elif current_algorithm == 'SPSO':
            position_history.append(spso.positions.copy())
        else:  # ARPSO
            position_history.append(arpso.positions.copy())
        
        
        if current_algorithm == 'APSO':
            pos, fit = run_one_iteration(apso, benchmark)
        elif current_algorithm == 'SPSO':
            pos, fit = run_one_iteration(spso, benchmark)
        else:  # ARPSO
            pos, fit = run_one_iteration(arpso, benchmark)
        
        if fit < best_global_fit:
            improvement = best_global_fit - fit
            algorithm_improvements[current_algorithm] += improvement
            best_global_fit = fit
            best_global_pos = pos
        
        if i % performance_window == 0 and i > 0:
            current_algorithm = max(algorithm_improvements, 
                                   key=algorithm_improvements.get)
            algorithm_improvements = {'APSO': 0, 'SPSO': 0, 'ARPSO': 0}
        
        history.append(best_global_fit)
    
    return best_global_pos, best_global_fit, history, position_history


def hybrid_particle_pso(benchmark, max_iter=200, num_particles=30):
    apso = APSO_CEC(num_particles=1, dim=benchmark.dim)
    spso = SPSO_CEC(num_particles=1, dim=benchmark.dim)
    arpso = ARPSO_CEC(num_particles=1, dim=benchmark.dim)
    
    # update rules: 10 APSO, 10 SPSO, 10 ARPSO
    particle_types = ['APSO'] * 10 + ['SPSO'] * 10 + ['ARPSO'] * 10
    
    positions = np.random.uniform(-100, 100, (num_particles, benchmark.dim))
    velocities = np.zeros((num_particles, benchmark.dim))
    accelerations = np.zeros((num_particles, benchmark.dim))
    
    fitness_values = np.array([benchmark.evaluate(pos) for pos in positions])
    b_positions = positions.copy()
    b_fitness = fitness_values.copy()
    g_index = np.argmin(fitness_values)
    g_position = positions[g_index].copy()
    g_fitness = fitness_values[g_index]
    
    history = [g_fitness]
    position_history = [positions.copy()]
    
    for i in range(max_iter):
        for j in range(num_particles):
            if particle_types[j] == 'APSO':
                accelerations[j] = apso.update_acceleration(
                    accelerations[j], positions[j], b_positions[j], g_position
                )
                velocities[j] = apso.update_velocity(velocities[j], accelerations[j])
                positions[j] = apso.update_position(positions[j], velocities[j])
            
            elif particle_types[j] == 'SPSO':
                velocities[j] = spso.update_velocity(
                    velocities[j], positions[j], b_positions[j], g_position
                )
                positions[j] = spso.update_positions(velocities[j], positions[j])
            
            else:  # ARPSO
                w = np.array([0.7])
                c3_values = np.array([0.1])
                attractive_pos = np.random.uniform(-100, 100, benchmark.dim)
                
                velocities[j] = arpso.update_velocity(
                    velocities[j], positions[j], b_positions[j], g_position,
                    attractive_pos, w, c3_values
                )
                positions[j] = arpso.update_position(positions[j], velocities[j])
        
        positions = np.clip(positions, -100, 100)
        
        fitness_values = np.array([benchmark.evaluate(pos) for pos in positions])
        
        improved = fitness_values < b_fitness
        b_positions[improved] = positions[improved].copy()
        b_fitness[improved] = fitness_values[improved]
        
        min_idx = np.argmin(fitness_values)
        if fitness_values[min_idx] < g_fitness:
            g_position = positions[min_idx].copy()
            g_fitness = fitness_values[min_idx]
        
        history.append(g_fitness)
        position_history.append(positions.copy())
    
    return g_position, g_fitness, history, position_history


def run_hybrid_with_tracking(hybrid_func, benchmark, max_iter):
    if hybrid_func == hybrid_sequential_pso:
        # Phase 1: Use APSO for fast initial convergence (40% of iterations)
        apso = APSO_CEC(num_particles=20, dim=benchmark.dim, max_iter=int(0.4*max_iter))
        apso_pos, apso_fit, _, apso_positions = apso.optimize(benchmark, int(0.4*max_iter))
        
        # Phase 2: Use SPSO for fine-tuning (60% of iterations)
        spso = SPSO_CEC(num_particles=20, dim=benchmark.dim, max_iter=int(0.6*max_iter))
        # Initialize SPSO particles around the APSO solution
        spso.positions = apso_pos + np.random.normal(0, 5, (20, benchmark.dim))
        spso.positions = np.clip(spso.positions, -100, 100)
        final_pos, final_fit, _, spso_positions = spso.optimize(benchmark, int(0.6*max_iter))
        
        # Combine position histories
        position_history = apso_positions + spso_positions
        return final_pos, final_fit, None, position_history
    
    # For parallel hybrid
    elif hybrid_func == hybrid_parallel_pso:
        # Create instances with equal particle distribution
        apso = APSO_CEC(num_particles=7, dim=benchmark.dim, max_iter=max_iter)
        spso = SPSO_CEC(num_particles=7, dim=benchmark.dim, max_iter=max_iter)
        arpso = ARPSO_CEC(num_particles=6, dim=benchmark.dim, max_iter=max_iter)
        
        # Initialize with same random positions for fair comparison
        initial_positions = np.random.uniform(-100, 100, (7, benchmark.dim))
        apso.positions = initial_positions.copy()
        spso.positions = initial_positions.copy()
        arpso.positions = initial_positions[:6].copy()  # Only 6 particles for ARPSO
        
        best_global_pos = None
        best_global_fit = float('inf')
        position_history = []
        
        for i in range(max_iter):
            # Get current positions
            all_positions = np.vstack([apso.positions, spso.positions, arpso.positions])
            position_history.append(all_positions)
            
            # Run one iteration of each algorithm
            apso_pos, apso_fit = run_one_iteration(apso, benchmark)
            spso_pos, spso_fit = run_one_iteration(spso, benchmark)
            arpso_pos, arpso_fit = run_one_iteration(arpso, benchmark)
            
            # Find best solution across all algorithms
            all_fits = [apso_fit, spso_fit, arpso_fit]
            all_pos = [apso_pos, spso_pos, arpso_pos]
            best_idx = np.argmin(all_fits)
            
            if all_fits[best_idx] < best_global_fit:
                best_global_fit = all_fits[best_idx]
                best_global_pos = all_pos[best_idx]
        
        return best_global_pos, best_global_fit, None, position_history
    
    # For adaptive hybrid
    elif hybrid_func == hybrid_adaptive_pso:
        # Create all algorithm instances
        apso = APSO_CEC(num_particles=20, dim=benchmark.dim, max_iter=max_iter)
        spso = SPSO_CEC(num_particles=20, dim=benchmark.dim, max_iter=max_iter)
        arpso = ARPSO_CEC(num_particles=20, dim=benchmark.dim, max_iter=max_iter)
        
        # Use same initial positions for all
        initial_positions = np.random.uniform(-100, 100, (20, benchmark.dim))
        apso.positions = initial_positions.copy()
        spso.positions = initial_positions.copy()
        arpso.positions = initial_positions.copy()
        
        # Track performance
        performance_window = 5  # How many iterations to consider for performance
        algorithm_improvements = {'APSO': 0, 'SPSO': 0, 'ARPSO': 0}
        
        best_global_pos = None
        best_global_fit = float('inf')
        position_history = []
        current_algorithm = 'APSO'  # Start with APSO for fast initial convergence
        
        for i in range(max_iter):
            # Get current positions based on active algorithm
            if current_algorithm == 'APSO':
                position_history.append(apso.positions.copy())
            elif current_algorithm == 'SPSO':
                position_history.append(spso.positions.copy())
            else:  # ARPSO
                position_history.append(arpso.positions.copy())
            
            # Run current algorithm
            if current_algorithm == 'APSO':
                pos, fit = run_one_iteration(apso, benchmark)
            elif current_algorithm == 'SPSO':
                pos, fit = run_one_iteration(spso, benchmark)
            else:  # ARPSO
                pos, fit = run_one_iteration(arpso, benchmark)
            
            # Update global best
            if fit < best_global_fit:
                improvement = best_global_fit - fit
                algorithm_improvements[current_algorithm] += improvement
                best_global_fit = fit
                best_global_pos = pos.copy()
            
            # Every few iterations, select best performing algorithm
            if i % performance_window == 0 and i > 0:
                current_algorithm = max(algorithm_improvements, 
                                    key=algorithm_improvements.get)
                # Reset improvement tracking
                algorithm_improvements = {'APSO': 0, 'SPSO': 0, 'ARPSO': 0}
                
                # Share the global best with all algorithms
                apso.update_global_best(best_global_pos, best_global_fit)
                spso.update_global_best(best_global_pos, best_global_fit)
                arpso.update_global_best(best_global_pos, best_global_fit)
        
        return best_global_pos, best_global_fit, None, position_history
    
    # For particle hybrid
    elif hybrid_func == hybrid_particle_pso:
        return hybrid_particle_pso(benchmark, max_iter, num_particles=20)
    
    else:
        raise ValueError(f"Unsupported hybrid function: {hybrid_func}")


def benchmark_hybrid_approaches(func_ids=[1, 2, 3, 4, 5], dim=10, runs=5, max_iter=200):
    results = {}
    
    algorithms = {
        "APSO": lambda: APSO_CEC(num_particles=30, dim=dim, max_iter=max_iter),
        "SPSO": lambda: SPSO_CEC(num_particles=30, dim=dim, max_iter=max_iter),
        "ARPSO": lambda: ARPSO_CEC(num_particles=30, dim=dim, max_iter=max_iter),
        "Sequential_Hybrid": lambda: hybrid_sequential_pso,
        "Parallel_Hybrid": lambda: hybrid_parallel_pso, 
        "Adaptive_Hybrid": lambda: hybrid_adaptive_pso, 
        "Particle_Hybrid": lambda: hybrid_particle_pso 
    }
    
    for func_id in func_ids:
        print(f"Testing function F{func_id}")
        benchmark = CEC2022Benchmark(func_num=func_id, dim=dim)
        
        func_results = {}
        for alg_name, alg_creator in algorithms.items():
            print(f"  Running {alg_name}...")
            alg_results = []
            convergence_data = []
            
            for run in range(runs):
                if alg_name in ["APSO", "SPSO", "ARPSO"]:
                    alg = alg_creator()
                    _, best_fitness, history, _ = alg.optimize(benchmark, max_iter)
                else:
                    hybrid_func = alg_creator()
                    _, best_fitness, history, _ = hybrid_func(benchmark, max_iter)
                
                alg_results.append(best_fitness)
                convergence_data.append(history)
                
                print(f"    Run {run + 1}/{runs}: {best_fitness:.2e}")
            
            func_results[alg_name] = {
                "mean": np.mean(alg_results),
                "std": np.std(alg_results),
                "min": np.min(alg_results),
                "max": np.max(alg_results),
                "median": np.median(alg_results),
                "convergence": np.mean(convergence_data, axis=0),
                "all_results": alg_results
            }
            
            print(f"  {alg_name} results: Mean={func_results[alg_name]['mean']:.2e}, Std={func_results[alg_name]['std']:.2e}")
        
        results[func_id] = func_results
    
    return results

def plot_hybrid_results(results):
    func_ids = list(results.keys())
    alg_names = list(results[func_ids[0]].keys())
    
    plt.figure(figsize=(14, 8))
    for alg_name in alg_names:
        means = [results[f][alg_name]["mean"] for f in func_ids]
        plt.semilogy(func_ids, means, label=alg_name, marker="o")
    
    plt.title("Mean Performance on CEC2022 Functions", fontsize=16)
    plt.xlabel("Function ID", fontsize=14)
    plt.ylabel("Mean Function Value (log scale)", fontsize=14)
    plt.xticks(func_ids)
    plt.grid(True)
    plt.legend(fontsize=12)
    plt.tight_layout()
    plt.savefig("hybrid_mean_performance.png", dpi=300)
    plt.show()
    
    for func_id in func_ids:
        plt.figure(figsize=(14, 8))
        for alg_name in alg_names:
            convergence = results[func_id][alg_name]["convergence"]
            plt.semilogy(range(len(convergence)), convergence, label=alg_name)
        
        plt.title(f"Convergence on Function F{func_id}", fontsize=16)
        plt.xlabel("Iterations", fontsize=14)
        plt.ylabel("Function Value (log scale)", fontsize=14)
        plt.grid(True)
        plt.legend(fontsize=12)
        plt.tight_layout()
        plt.savefig(f"hybrid_convergence_f{func_id}.png", dpi=300)
        plt.show()
    

    summary = {}
    for func_id in func_ids:
        best_alg = min(alg_names, key=lambda x: results[func_id][x]["mean"])
        best_mean = results[func_id][best_alg]["mean"]
        
        summary[func_id] = {
            "best_algorithm": best_alg,
            "best_mean": best_mean,
            "relative_performance": {}
        }
        
        for alg_name in alg_names:
        
            rel_perf = results[func_id][alg_name]["mean"] / best_mean
            summary[func_id]["relative_performance"][alg_name] = rel_perf
    

    print("\nPerformance Summary (lower is better):")
    print("-" * 80)
    print(f"{'Function':<10} {'Best Algorithm':<20} {'Best Mean':<15} {'Relative Performance'}")
    print("-" * 80)
    
    for func_id in func_ids:
        s = summary[func_id]
        rel_perf_str = " | ".join([f"{alg}: {s['relative_performance'][alg]:.2f}x" for alg in alg_names])
        print(f"F{func_id:<9} {s['best_algorithm']:<20} {s['best_mean']:.2e} {rel_perf_str}")
    
    return summary


def statistical_analysis(results):
    func_ids = list(results.keys())
    alg_names = list(results[func_ids[0]].keys())
    
    print("\nStatistical Significance Analysis (Wilcoxon signed-rank test):")
    print("-" * 80)
    
    for func_id in func_ids:
        print(f"\nFunction F{func_id}:")
        
        standard_algs = ["APSO", "SPSO", "ARPSO"]
        best_standard = min(standard_algs, key=lambda x: results[func_id][x]["mean"])
        best_standard_results = results[func_id][best_standard]["all_results"]
        
        # compare hybrid algos to best standard
        hybrid_algs = [a for a in alg_names if a not in standard_algs]
        
        for hybrid in hybrid_algs:
            hybrid_results = results[func_id][hybrid]["all_results"]
            
            # perform Wilcoxon test
            stat, p_value = stats.wilcoxon(hybrid_results, best_standard_results)
            
            # determine if hybrid is better
            is_better = np.mean(hybrid_results) < np.mean(best_standard_results)
            
            significance = "significant" if p_value < 0.05 else "not significant"
            direction = "better than" if is_better else "worse than"
            
            print(f"  {hybrid} vs {best_standard}: {direction} (p={p_value:.4f}, {significance})")


def analyze_convergence_speed(results):
    func_ids = list(results.keys())
    alg_names = list(results[func_ids[0]].keys())
    
    print("\nConvergence Speed Analysis (iterations to reach 5% of final value):")
    print("-" * 80)
    
    for func_id in func_ids:
        print(f"\nFunction F{func_id}:")
        
        for alg_name in alg_names:
            convergence = results[func_id][alg_name]["convergence"]
            final_value = convergence[-1]
            target_value = final_value * 1.05  # Within 5% of final
            
            # Find first iteration that reaches target
            for i, value in enumerate(convergence):
                if value <= target_value:
                    break
            
            print(f"  {alg_name}: {i} iterations")


def create_comprehensive_comparison(results, summary):
    func_ids = list(results.keys())
    alg_names = list(results[func_ids[0]].keys())
    
    wins = {alg: 0 for alg in alg_names}
    for func_id in func_ids:
        best_alg = summary[func_id]["best_algorithm"]
        wins[best_alg] += 1
    
    ranks = {alg: [] for alg in alg_names}
    for func_id in func_ids:
        sorted_algs = sorted(alg_names, 
                            key=lambda x: results[func_id][x]["mean"])
        
        for rank, alg in enumerate(sorted_algs, 1):
            ranks[alg].append(rank)
    
    avg_ranks = {alg: np.mean(r) for alg, r in ranks.items()}
    
    print("\nComprehensive Algorithm Comparison:")
    print("-" * 80)
    print(f"{'Algorithm':<20} {'Wins':<10} {'Avg Rank':<10} {'Best Functions'}")
    print("-" * 80)
    
    for alg in sorted(alg_names, key=lambda x: avg_ranks[x]):
        best_funcs = [f for f in func_ids if summary[f]["best_algorithm"] == alg]
        best_funcs_str = ", ".join([f"F{f}" for f in best_funcs]) if best_funcs else "None"
        
        print(f"{alg:<20} {wins[alg]:<10} {avg_ranks[alg]:.2f}      {best_funcs_str}")


def compare_hybrid_trajectories(algorithms, benchmark, max_iter=50, func_id=1):
    if benchmark.dim != 2:
        print("Trajectory comparison only works for 2D problems")
        return
    
    fig, axes = plt.subplots(1, len(algorithms), figsize=(5*len(algorithms), 5))
    if len(algorithms) == 1:
        axes = [axes]
    
    x = np.linspace(-100, 100, 100)
    y = np.linspace(-100, 100, 100)
    X, Y = np.meshgrid(x, y)
    Z = np.zeros_like(X)
    
    for i in range(X.shape[0]):
        for j in range(X.shape[1]):
            Z[i, j] = benchmark.evaluate(np.array([X[i, j], Y[i, j]]))
    
    # optimization for each algorithm
    for i, (alg_name, algorithm) in enumerate(algorithms.items()):
        if alg_name in ["APSO", "SPSO", "ARPSO"]:
            # Standard algorithm
            _, _, _, position_history = algorithm.optimize(benchmark, max_iter)
        else:
            _, _, _, position_history = run_hybrid_with_tracking(algorithm, benchmark, max_iter)
        
        contour = axes[i].contourf(X, Y, Z, 50, cmap="viridis", alpha=0.8)  # noqa: F841
        
        global_best_positions = []
        for frame in range(len(position_history)):
            positions = position_history[frame]
            fitness_values = np.array([benchmark.evaluate(pos) for pos in positions])
            best_idx = np.argmin(fitness_values)
            global_best_positions.append(positions[best_idx])
        
        global_best_positions = np.array(global_best_positions)
        axes[i].plot(
            global_best_positions[:, 0], global_best_positions[:, 1], "r-", linewidth=2
        )
        axes[i].scatter(
            global_best_positions[-1, 0],
            global_best_positions[-1, 1],
            c="white",
            s=100,
            marker="*",
        )
        
        axes[i].set_xlabel("X")
        axes[i].set_ylabel("Y")
        axes[i].set_title(f"{alg_name} on F{func_id}")
    
    plt.tight_layout()
    plt.savefig(f"hybrid_trajectory_comparison_f{func_id}.png", dpi=300)
    plt.show()



hybrid_results = benchmark_hybrid_approaches(func_ids=[1, 2, 3, 4, 5], dim=10, runs=5, max_iter=200)

with open('hybrid_results.pkl', 'wb') as f:
    pickle.dump(hybrid_results, f)

summary = plot_hybrid_results(hybrid_results)

statistical_analysis(hybrid_results)

analyze_convergence_speed(hybrid_results)

create_comprehensive_comparison(hybrid_results, summary)

dim = 10
func_ids = [1, 2, 3, 4, 5]

if dim >= 2:
    for func_id in func_ids:
        benchmark_2d = CEC2022Benchmark(func_num=func_id, dim=2)
        
        algorithms_2d = {
            "APSO": APSO_CEC(num_particles=20, dim=2, max_iter=50),
            "SPSO": SPSO_CEC(num_particles=20, dim=2, max_iter=50),
            "ARPSO": ARPSO_CEC(num_particles=20, dim=2, max_iter=50),
            "Sequential_Hybrid": hybrid_sequential_pso,
            "Parallel_Hybrid": hybrid_parallel_pso,
            "Adaptive_Hybrid": hybrid_adaptive_pso,
            "Particle_Hybrid": hybrid_particle_pso
        }
        
        compare_hybrid_trajectories(algorithms_2d, benchmark_2d, max_iter=50, func_id=func_id)